{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all the image paths and label text from gt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23a1b04f26349188d01721d511392a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/backup2/synthtiger/arabic/horizontal_50lk_part2/gt.txt has : 4729991  data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad39a65522f41dab64a08a27015d323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4729991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/backup2/synthtiger/arabic/horizontal_fifty_lakh_ar/gt.txt has : 4734048  data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f54950bdd44aa189b297ab00c44dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4734048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/backup2/synthtiger/arabic/horizontal_one_cr/gt.txt has : 9467101  data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2314272e94af292ee42dfd913d805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9467101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from glob import glob \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dirs=[  '/backup2/synthtiger/arabic/horizontal_50lk_part2/',\n",
    "        '/backup2/synthtiger/arabic/horizontal_fifty_lakh_ar/',\n",
    "        '/backup2/synthtiger/arabic/horizontal_one_cr/',\n",
    "        ]\n",
    "\n",
    "image_paths=[]\n",
    "labels=[]\n",
    "for _dir in tqdm(dirs):\n",
    "    _txt=os.path.join(_dir,\"gt.txt\")\n",
    "    with open(_txt,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "    print(_txt, \"has :\",len(lines),\" data\")\n",
    "    for line in tqdm(lines):\n",
    "        if line.strip():\n",
    "            if len(line.split(\"\\t\"))==2:\n",
    "                line=line.replace(\"\\n\",\"\")\n",
    "                _path,_label=line.split(\"\\t\")\n",
    "                _path=_dir+_path\n",
    "                image_paths.append(_path)\n",
    "                labels.append(_label)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all charecters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78da5ebd75e4508938ce402f4475dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18931140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'ك','د','ر','ب','ي','ت','و','ا','ن','س','ه','م','ج','ل','ف','ع','ذ','ح','ص','ى',\n",
      "'ز','أ','ق','ض','خ','ش','غ','ط','ة','إ','ظ','ئ','ث','آ','ء','ؤ',"
     ]
    }
   ],
   "source": [
    "chars=[]\n",
    "for label in tqdm(labels):\n",
    "    for c in label:\n",
    "        if c not in chars:\n",
    "            chars.append(c)\n",
    "for idx,c in enumerate(chars):\n",
    "    if idx%20==0:\n",
    "        print()\n",
    "    print(f\"'{c}'\",end=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dict and match unicodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'٠','١','٢','٣','٤','٥','٦','٧','٨','٩','«','»','؟','،','؛','ء','آ','أ','ؤإ','ئا',\n",
      "'اً','ب','ة','ت','ث','ج','ح','خ','د','ذ','ر','ز','س','ش','ص','ض','ط','ظ','ع','غ',\n",
      "'ف','ق','ك','ل','م','ن','ه','و','ى','ي','ً','ٌ','ٍ','َ','ُ','ِ','ّ','ْ','ٓ','ٔ',\n",
      "'ٰ','ٱ','ٹ','پ','چ','ڈ','ڑ','ژ','ک','ڭ','گ','ں','ھ','ۀ','ہ','ۂ','ۃ','ۆ','ۇ','ۈ',\n",
      "'ۋ','ی','ې','ے','ۓ','ە',"
     ]
    }
   ],
   "source": [
    "def get_vocab(vocab_txt):\n",
    "    vocab=[]\n",
    "    with open(vocab_txt,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            vocab.append(line.strip())\n",
    "    return vocab\n",
    "\n",
    "dict_vocab=get_vocab(\"../vocabs/ar.txt\")\n",
    "for idx,c in enumerate(dict_vocab):\n",
    "    if idx%20==0:\n",
    "        print()\n",
    "    print(f\"'{c}'\",end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in dataset but not present in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ا','إ','ئ','ؤ',"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in chars:\n",
    "    if c not in dict_vocab:\n",
    "         print(f\"'{c}'\",end=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in vocab but not present in chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'٠','١','٢','٣','٤','٥','٦','٧','٨','٩','«','»','؟','،','؛','ؤإ','ئا','اً','ً','ٌ','ٍ','َ','ُ','ِ','ّ','ْ','ٓ','ٔ','ٰ','ٱ','ٹ','پ','چ','ڈ','ڑ','ژ','ک','ڭ','گ','ں','ھ','ۀ','ہ','ۂ','ۃ','ۆ','ۇ','ۈ','ۋ','ی','ې','ے','ۓ','ە',"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in dict_vocab:\n",
    "    if c not in chars:\n",
    "        print(f\"'{c}'\",end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bangla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83cb0fe33a0a67f9f877ffb776c4b7cce63e124f7ba47fe6878fb868bcc96314"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
